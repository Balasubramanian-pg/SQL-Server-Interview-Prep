# 11. Columnstore Index: Compressed Storage

Canonical documentation for [11. Columnstore Index: Compressed Storage](4. Indexing Deep Dive/11. Columnstore Index: Compressed Storage.md). This document defines concepts, terminology, and standard usage.

## Purpose
The primary purpose of Columnstore Indexing is to optimize the storage and retrieval of large-scale data sets, typically for analytical processing (OLAP). By organizing data by column rather than by row, this storage model achieves significantly higher compression ratios and reduces the physical I/O required to satisfy queries that only reference a subset of columns.

This topic addresses the "I/O bottleneck" inherent in traditional row-based storage when performing aggregations, filtering, and large-scale scans.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural principles of columnar compression rather than specific database engine syntax.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Physical storage structures (Segments and Rowgroups).
> * Compression techniques (Dictionary, RLE, Bit-packing).
> * Performance implications of columnar data layout.
> * Theoretical lifecycle of data within a compressed columnstore.

> [!WARNING]
> **Out of scope:**
> * Specific vendor-specific syntax (e.g., T-SQL, PL/SQL).
> * Hardware-level disk formatting or RAID configurations.
> * In-memory-only columnar structures (unless they persist to disk).

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| **Rowgroup** | A logical grouping of rows (typically around one million) that are processed together into a columnar format. |
| **Segment** | The unit of storage for a single column within a Rowgroup. A Columnstore Index is composed of many segments. |
| **Dictionary Encoding** | A compression technique where unique values are replaced with smaller integer keys, and a separate dictionary maps keys back to values. |
| **Run-Length Encoding (RLE)** | A compression method that stores a value and a count for consecutive identical values, highly effective in sorted columnar data. |
| **Delta Store** | A temporary row-based storage area used to accumulate small inserts before they are compressed into columnar segments. |
| **Vectorized Execution** | A query processing method where operations are performed on a batch of values (a vector) from a column segment at once, rather than row-by-row. |

## Core Concepts
The fundamental shift in Columnstore storage is the transition from "Row-Major" to "Column-Major" orientation.

### Columnar vs. Row-based Storage
In a row-based system, all data for a single record is stored contiguously. In a columnstore, all data for a single attribute (column) across many records is stored contiguously. This allows the system to skip entire columns that are not requested by a query.

### Compression Mechanics
Because data within a column is of the same data type and often contains repetitive values, compression algorithms are significantly more effective than in row-based storage.
*   **Bit-packing:** Reducing the number of bits used to store integers based on the range of values in the segment.
*   **Value-based Scaling:** Storing a base value and only recording the offsets for each entry.

> [!TIP]
> Think of a row-based index like a stack of business cards; to find all phone numbers, you must flip through every card. A columnstore index is like a spreadsheet where each column is printed on a separate strip of paper; to find phone numbers, you only pick up the "Phone" strip and ignore the rest.

## Standard Model
The standard model for Columnstore Compressed Storage follows a specific lifecycle to balance write performance with read optimization:

1.  **Ingestion (Delta Store):** New data often enters a "Delta Store" (a traditional B-Tree/Row-based structure). This prevents the high overhead of re-compressing segments for every single row insert.
2.  **Tuple Mover / Background Process:** Once a Delta Store reaches a threshold (the "closed" state), a background process compresses the rows into a new Rowgroup.
3.  **Columnar Compression:** During compression, the data is sorted (optionally), encoded via dictionaries or RLE, and written to disk as segments.
4.  **Metadata Management:** The system maintains min/max values for each segment (Segment Elimination), allowing the query engine to skip segments that do not contain relevant data.

## Common Patterns
*   **Partitioning:** Aligning columnstore indexes with table partitioning to allow for efficient data lifecycle management (e.g., dropping old partitions).
*   **Archival Compression:** Applying higher-latency, higher-ratio compression algorithms to "cold" data that is rarely accessed but must be retained.
*   **Star Schema Optimization:** Using columnstores on large Fact tables while keeping Dimension tables in row-based formats to optimize join performance.

## Anti-Patterns
*   **Frequent Single-Row Updates:** Updating a single row in a compressed segment requires decompressing, modifying, and re-compressing the entire segment, or managing complex "delete bitmaps."
*   **Small Batch Inserts:** Inserting data in very small increments leads to a fragmented Delta Store and prevents the formation of high-quality compressed segments.
*   **Over-indexing:** Creating a columnstore on a table with very few rows (e.g., less than 100,000) often results in worse performance than a standard row-based index due to the overhead of the columnar metadata.

> [!CAUTION]
> Avoid using Columnstore indexes for OLTP workloads characterized by high-concurrency, small-lookup transactions. The overhead of managing compressed segments will lead to significant "latch contention" and performance degradation.

## Edge Cases
*   **High-Cardinality Columns:** Columns with unique values (like GUIDs or high-precision timestamps) do not compress well using dictionary encoding or RLE, potentially leading to larger storage footprints than expected.
*   **Dictionary Pressure:** If a segment contains too many unique strings, the dictionary may exceed memory limits, forcing the system to fall back to less efficient encoding methods.
*   **Tombstoned Rows:** When rows are deleted, they are often marked in a "delete bitmap" rather than physically removed from the compressed segment. A high percentage of deleted rows can degrade scan performance until a "reorganize" or "rebuild" operation is performed.

## Related Topics
*   **Vectorized Query Execution:** The processing model that leverages columnar data layouts.
*   **Segment Elimination:** The process of using metadata to skip irrelevant data blocks.
*   **OLAP vs. OLTP:** The fundamental architectural distinction driving the need for columnar storage.
*   **Data Warehousing:** The primary use case for compressed columnstore technology.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-13 | Initial AI-generated canonical documentation |