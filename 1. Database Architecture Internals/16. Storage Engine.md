# 16. Storage Engine

Canonical documentation for [16. Storage Engine](1. Database Architecture Internals/16. Storage Engine.md). This document defines concepts, terminology, and standard usage.

## Purpose
The Storage Engine is the core software component of a data management system responsible for the physical handling of data. It acts as the intermediary between the high-level query interface and the underlying storage medium (disk, memory, or cloud-native storage). 

The primary purpose of a storage engine is to manage how data is stored, indexed, updated, and retrieved while ensuring data integrity and performance. By decoupling the storage mechanics from the query processing layer, systems can optimize for specific workloads—such as high-write throughput, rapid analytical scanning, or low-latency point lookups—without altering the application-level logic.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural principles that govern all storage engines regardless of the specific database management system (DBMS).

## Scope
The scope of this document covers the internal mechanics and theoretical frameworks of storage engines.

> [!IMPORTANT]
> **In scope:**
> * Data persistence and durability mechanisms.
> * Indexing structures and search algorithms.
> * Concurrency control and locking strategies at the storage level.
> * Buffer management and caching strategies.
> * Physical data layout (Row-based vs. Columnar).

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., InnoDB, RocksDB, WiredTiger).
> * Query parsing, optimization, and execution plans.
> * Network protocols and client-server communication.
> * Hardware-level driver development.

## Definitions
| Term | Definition |
|------|------------|
| **Write-Ahead Log (WAL)** | A family of techniques for providing atomicity and durability by logging changes to a non-volatile serial file before applying them to the main data store. |
| **Page / Block** | The smallest unit of data transfer between the storage engine and the physical storage medium. |
| **Buffer Pool** | A region of memory used to cache data pages to reduce the frequency of expensive I/O operations. |
| **Compaction** | The process of reclaiming space and reorganizing data, typically found in Log-Structured Merge (LSM) engines. |
| **Data Locality** | The physical proximity of related data on storage media, which significantly impacts retrieval performance. |
| **Checkpointing** | The process of flushing modified data from memory to persistent storage to synchronize the state and truncate logs. |

## Core Concepts
The storage engine operates on the principle of balancing the "CAP" trade-offs (Consistency, Availability, Partition Tolerance) and the "RUM" conjecture (Read overhead, Update overhead, Memory/Storage overhead).

### Data Persistence
Storage engines must ensure that once a transaction is committed, it remains so even in the event of a system failure. This is typically achieved through a combination of WAL and periodic flushing of the buffer pool.

### Concurrency Control
To allow multiple processes to access data simultaneously, storage engines implement isolation levels. This involves managing locks (shared or exclusive) or utilizing Multi-Version Concurrency Control (MVCC) to provide snapshots of data at specific points in time.

> [!TIP]
> Think of a storage engine like a library's filing system. The "Query Layer" is the librarian who understands your request, but the "Storage Engine" is the physical arrangement of books on shelves and the card catalog that tells the librarian exactly which aisle and shelf to visit.

## Standard Model
The standard model of a storage engine follows a layered architecture:

1.  **API Layer:** Provides the interface for the query processor to perform CRUD (Create, Read, Update, Delete) operations.
2.  **Buffer Manager:** Manages the movement of data pages between memory and disk, implementing eviction policies like LRU (Least Recently Used).
3.  **Transaction Manager:** Ensures ACID compliance by coordinating locks and logging.
4.  **Index Manager:** Maintains data structures (like B-Trees or Hash Maps) to accelerate data retrieval.
5.  **Space Manager:** Handles the allocation and deallocation of physical blocks on the storage medium.

## Common Patterns
Storage engines generally fall into three primary architectural patterns:

*   **B+ Tree Engines:** Optimized for read-heavy workloads and range scans. They maintain a balanced tree structure where all data resides in the leaf nodes.
*   **Log-Structured Merge (LSM) Trees:** Optimized for write-heavy workloads. They treat all updates as appends to an immutable log, periodically merging and compacting files in the background.
*   **Columnar Storage:** Optimized for analytical processing (OLAP). Data is stored by column rather than row, allowing for high compression ratios and efficient scanning of specific attributes across billions of records.

## Anti-Patterns
*   **Direct File Manipulation:** Bypassing the storage engine's API to modify underlying data files, which leads to corruption and loss of ACID guarantees.
*   **Oversized Pages:** Defining page sizes that are significantly larger than the underlying hardware's block size, leading to "write amplification" and wasted I/O.
*   **Ignoring Workload Alignment:** Using a write-optimized engine (LSM) for a workload that is 99% random reads, or vice versa.

> [!CAUTION]
> Avoid tight coupling between the application logic and the specific storage engine's physical file format. This creates "vendor lock-in" at the binary level and prevents future migrations or optimizations.

## Edge Cases
*   **Partial Writes (Torn Pages):** Occurs when a system fails mid-way through writing a page to disk. Storage engines must use "double-write buffers" or checksums to detect and repair these.
*   **Bit Rot:** Physical degradation of storage media over time. Canonical storage engines implement background "scrubbing" to verify checksums and relocate data if corruption is detected.
*   **Clock Skew:** In distributed storage engines, discrepancies between system clocks can lead to incorrect versioning in MVCC systems.

## Related Topics
*   **15. Transaction Management:** The higher-level logic that coordinates multiple storage engine operations.
*   **17. Indexing Strategies:** Detailed exploration of the data structures used within storage engines.
*   **22. Data Persistence:** The physical hardware and filesystem layer beneath the storage engine.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |