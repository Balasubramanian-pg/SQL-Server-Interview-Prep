# 11. Transaction Log Architecture

Canonical documentation for [11. Transaction Log Architecture](1. Database Architecture Internals/11. Transaction Log Architecture.md). This document defines concepts, terminology, and standard usage.

## Purpose
The Transaction Log (also known as a Write-Ahead Log or WAL) exists to ensure data integrity, atomicity, and durability in a database system. It addresses the fundamental problem of maintaining a consistent state in the event of system crashes, hardware failures, or unexpected interruptions. By recording changes before they are permanently applied to the main data files, the transaction log provides a verifiable audit trail and a mechanism for state reconstruction.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural principles that govern transactional logging across relational, non-relational, and distributed systems.

## Scope
This document covers the logical structure, operational flow, and recovery mechanisms inherent in transaction log architectures.

> [!IMPORTANT]
> **In scope:**
> * Write-Ahead Logging (WAL) protocols
> * Log sequence management and synchronization
> * Recovery procedures (Redo/Undo logic)
> * Log truncation and archival strategies

> [!WARNING]
> **Out of scope:**
> * Specific vendor file formats (e.g., `.ldf`, `.ib_logfile`)
> * Cloud-provider specific managed logging services
> * Application-level event sourcing (unless used as a primary persistence layer)

## Definitions
| Term | Definition |
|------|------------|
| Write-Ahead Logging (WAL) | A family of techniques for providing atomicity and durability by ensuring that changes are recorded in a log before they are applied to the database. |
| Log Sequence Number (LSN) | A unique, monotonically increasing identifier assigned to every record in the transaction log to maintain strict ordering. |
| Checkpoint | A synchronization point where the system ensures all log records and modified data pages up to a certain LSN are flushed to persistent storage. |
| Redo | The process of re-applying committed transactions from the log to the data files during recovery. |
| Undo | The process of reversing uncommitted or rolled-back transactions found in the log during recovery. |
| Tail of the Log | The most recent portion of the transaction log that has not yet been backed up or truncated. |

## Core Concepts
The transaction log is fundamentally an append-only, sequential record of all modifications made to a system. Unlike data files, which involve random I/O to update specific records, the transaction log leverages sequential I/O, which is significantly more performant on most storage media.

### The Durability Guarantee
The primary role of the log is to satisfy the "D" in ACID (Atomicity, Consistency, Isolation, Durability). A transaction is considered "hardened" or committed only once its log record has been successfully flushed to non-volatile storage.

### Idempotency in Recovery
Recovery processes must be idempotent. If a system crashes during a recovery operation, the subsequent recovery attempt must be able to resume or restart without corrupting the state, regardless of how many times the redo/undo operations are applied.

> [!TIP]
> Think of the transaction log as a "black box" flight recorder for a database. While the data files represent the current physical state of the aircraft, the log records every movement and command that led to that state.

## Standard Model
The standard model for transaction log architecture follows the Write-Ahead Logging (WAL) protocol. The lifecycle of a transaction within this model typically follows these steps:

1.  **Log Buffer Entry:** When a change is requested, a record is created in an in-memory log buffer.
2.  **Data Buffer Modification:** The corresponding data page in the memory cache is modified (becoming a "dirty page").
3.  **Log Flush:** Before the transaction is acknowledged as successful, the log buffer is flushed to persistent storage.
4.  **Commit Acknowledgment:** The system confirms the transaction to the client.
5.  **Lazy Writing:** At a later time, the dirty data pages are written to the main data files (often during a checkpoint).

> [!IMPORTANT]
> The data file may contain uncommitted changes or lack committed changes at any given moment. The transaction log is the ultimate "Source of Truth" used to reconcile these discrepancies during startup.

## Common Patterns
### Log Shipping
A high-availability pattern where transaction log backups are periodically sent from a primary server to one or more standby servers. The standby servers "replay" the logs to maintain a near-real-time copy of the data.

### Point-in-Time Recovery (PITR)
By maintaining a continuous chain of transaction logs and a full baseline backup, administrators can restore a database to its exact state at any specific microsecond by replaying the logs up to that point.

### Change Data Capture (CDC)
Using the transaction log as a source for downstream systems. Instead of querying the database for changes, a reader parses the log to identify inserts, updates, and deletes to stream to data warehouses or search indexes.

## Anti-Patterns
### Synchronous Logging on High-Latency Storage
Placing transaction logs on storage with high seek times or network latency can bottleneck the entire system, as every commit must wait for a physical disk flush.

### Manual Log Modification
Attempting to manually edit or "fix" a transaction log file. Because logs rely on strict LSN chaining and checksums, manual intervention almost invariably leads to catastrophic data corruption.

### Circular Log Overlap
Configuring a circular log (where old records are overwritten) that is too small for the transaction volume. This can lead to "log wrap-around" where the system overwrites records needed for an active transaction or recovery.

> [!CAUTION]
> Never place transaction logs and data files on the same physical disk spindle or volume if performance and redundancy are priorities. This creates a single point of failure and induces I/O contention.

## Edge Cases
### Log Full Scenarios
When the storage medium for the transaction log reaches capacity, the database must halt all modification operations. In many architectures, the database will transition to a read-only state or shut down entirely to prevent data loss.

### Partial Log Writes (Torn Pages)
A hardware or power failure might occur while a log record is being written. Robust architectures use checksums and "double-write" buffers to detect and discard these partial entries during the recovery phase.

### Long-Running Transactions
A single transaction that remains open for an extended period prevents the log from being truncated. This can cause the log to grow indefinitely, even if the total volume of data in the database is small.

## Related Topics
*   **ACID Compliance:** The theoretical framework that transaction logs help implement.
*   **Buffer Pool Management:** How memory is managed in conjunction with log flushes.
*   **Checkpointing Algorithms:** The logic governing when data is hardened to disk.
*   **Replication Topologies:** How logs are distributed across a network.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |