# 42. Metadata Discovery

Canonical documentation for [42. Metadata Discovery](1. Database Architecture Internals/42. Metadata Discovery.md). This document defines concepts, terminology, and standard usage.

## Purpose
Metadata Discovery is the systematic process of identifying, capturing, and indexing descriptive information about data assets, services, and digital resources within an ecosystem. Its primary purpose is to solve the "dark data" problemâ€”where information exists but remains inaccessible or unknown to potential consumers. 

By establishing a mechanism for discovery, organizations can ensure data visibility, facilitate governance, and enable automated interoperability between disparate systems. This topic addresses the challenge of maintaining an accurate, up-to-date inventory of assets in environments characterized by high velocity, volume, and variety.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural and procedural requirements of discovery rather than specific software solutions.

## Scope
The scope of Metadata Discovery encompasses the lifecycle of metadata identification from the source to a centralized or federated repository.

> [!IMPORTANT]
> **In scope:**
> * Mechanisms for automated and manual metadata extraction.
> * Classification and categorization of discovered assets.
> * Maintenance of metadata freshness and accuracy.
> * Relationship mapping between discovered entities (lineage and dependencies).

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., AWS Glue, Alation, Collibra).
> * Data storage optimization or physical data movement.
> * End-user data analysis or business intelligence reporting.

## Definitions
| Term | Definition |
|------|------------|
| Metadata | Data that provides information about other data, including structural, administrative, and descriptive attributes. |
| Crawler/Scanner | An automated process that traverses a system to identify assets and extract their metadata. |
| Catalog | A centralized repository where discovered metadata is organized, indexed, and made searchable. |
| Semantic Discovery | The process of identifying the meaning or context of data through pattern matching or machine learning. |
| Introspection | The ability of a system to provide metadata about its own structure or state upon request. |
| Lineage | The historical record of an asset's origin, transformations, and movement over time. |

## Core Concepts
Metadata Discovery relies on the ability to bridge the gap between raw data storage and human or machine consumption.

### Passive vs. Active Discovery
*   **Passive Discovery:** Relies on manual entry or scheduled batch processes to update the metadata repository. It is often less resource-intensive but risks becoming outdated.
*   **Active Discovery:** Utilizes event-driven triggers or continuous monitoring to update metadata in real-time as assets are created, modified, or deleted.

### Technical vs. Business Metadata
Discovery must account for different layers of information:
1.  **Technical:** Schema names, data types, file sizes, and permissions.
2.  **Business:** Ownership, sensitivity levels (PII/GDPR), and business definitions.

> [!TIP]
> Think of Metadata Discovery as a library's indexing system. Without it, the library is merely a room full of paper; with it, it becomes a searchable, navigable resource where the "card catalog" (metadata) points the way to the "books" (data).

## Standard Model
The standard model for Metadata Discovery follows a four-stage pipeline:

1.  **Observation:** The discovery agent identifies a target system (database, API, file system).
2.  **Extraction:** The agent performs introspection or scans the source to pull raw metadata.
3.  **Normalization:** The extracted metadata is converted into a standardized format (e.g., JSON-LD, Dublin Core) to ensure consistency across different sources.
4.  **Ingestion:** The normalized metadata is indexed into a Catalog or Metadata Management System for consumption.

## Common Patterns
*   **Pull-Based Scanning:** A central discovery engine reaches out to registered sources on a schedule to "pull" metadata.
*   **Push-Based Registration:** Source systems are configured to "push" their metadata to a central registry whenever a change occurs (e.g., via Webhooks or Message Queues).
*   **Sidecar Discovery:** In microservices architectures, a secondary process runs alongside the service to broadcast its metadata and health status to a discovery service.
*   **Crowdsourced Enrichment:** Allowing end-users to tag, rate, or comment on discovered assets to add "social metadata" that automated scanners cannot detect.

## Anti-Patterns
*   **The "Black Box" Catalog:** Collecting metadata without providing an interface for discovery, leading to a repository that is populated but never utilized.
*   **Manual-Only Updates:** Relying exclusively on human intervention to document assets, which inevitably leads to "metadata rot" as the underlying data evolves.
*   **Over-Collection (Metadata Bloat):** Capturing every possible attribute of a system, including transient or irrelevant logs, which obscures useful information and increases storage costs.

> [!CAUTION]
> Avoid tight coupling between the discovery agent and the source system's internal schema. If the source schema changes and the agent is not resilient, the discovery pipeline will fail, leading to a loss of visibility.

## Edge Cases
*   **Transient Assets:** Short-lived data (e.g., temporary tables in an ETL process) may appear and disappear between discovery cycles, leading to "ghost" metadata or missed entries.
*   **Encrypted/Opaque Metadata:** Systems that encrypt their headers or use proprietary binary formats may prevent scanners from extracting meaningful structural information.
*   **Legacy Systems:** Older systems lacking APIs or standard query interfaces may require custom-built "wrappers" to facilitate discovery.
*   **Polyglot Environments:** Discovery across heterogeneous environments (e.g., mixing NoSQL, RDBMS, and Flat Files) requires complex normalization logic to maintain a unified view.

## Related Topics
*   **41. Data Governance:** The framework of rules and roles that Metadata Discovery supports.
*   **43. Data Lineage:** The specific subset of discovery focused on the flow and transformation of data.
*   **12. API Management:** Often involves service discovery, a specialized form of metadata discovery for functional endpoints.
*   **50. Data Sovereignty:** Concerns regarding where metadata is stored and who has the right to "discover" it.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |