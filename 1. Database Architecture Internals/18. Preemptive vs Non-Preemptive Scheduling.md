# 18. Preemptive vs Non Preemptive Scheduling

Canonical documentation for 18. Preemptive vs Non Preemptive Scheduling. This document defines concepts, terminology, and standard usage.

## Purpose
The primary purpose of CPU scheduling is to maximize resource utilization and ensure system responsiveness by managing how processes access the Central Processing Unit (CPU). In a multi-programmed environment, the scheduler must decide which process in the "Ready" state should be allocated the CPU next. 

The distinction between preemptive and non-preemptive scheduling addresses the fundamental strategy of resource control: whether the operating system has the authority to forcibly remove a running process from the CPU or if it must wait for the process to relinquish control voluntarily.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural implications of scheduling disciplines.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Theoretical mechanisms of process interruption and voluntary yielding.
> * Impact on system metrics such as throughput, latency, and turnaround time.
> * State transition logic within the process lifecycle.
> * Comparative analysis of scheduling overhead.

> [!WARNING]
> **Out of scope:**
> * Specific kernel-level source code implementations (e.g., Linux CFS or Windows Scheduler internals).
> * Hardware-specific interrupt controller configurations.
> * Detailed analysis of multi-core affinity or NUMA-aware scheduling.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Preemption | The act of the operating system interrupting a currently running process to assign the CPU to another process without the current process's consent. |
| Non-Preemption | A scheduling discipline where a process holds the CPU until it either terminates or transitions to a "Waiting" state (e.g., for I/O). |
| Context Switch | The procedure of saving the state (context) of a running process and loading the saved state of another process. |
| Time Quantum | A fixed interval of time (time slice) assigned to a process in preemptive systems. |
| Throughput | The number of processes that complete their execution per unit of time. |
| Response Time | The time from the submission of a request until the first response is produced. |
| Starvation | A condition where a process is perpetually denied necessary resources to process its work. |

## Core Concepts
The core of the debate between preemptive and non-preemptive scheduling lies in the balance between **overhead** and **fairness**.

### The Mechanism of Control
In a **Non-Preemptive** system, the scheduler is passive. Once a process enters the "Running" state, it stays there until it finishes its task or requests an I/O operation. This is often referred to as "Cooperative Scheduling."

In a **Preemptive** system, the scheduler is active. It utilizes a hardware timer to trigger interrupts. When the timer expires, the scheduler regains control, evaluates the priority of all ready processes, and may perform a context switch.

> [!TIP]
> Think of a Non-Preemptive system like a single-lane bridge where a car only leaves the bridge once it reaches the other side. A Preemptive system is like a traffic light at an intersection that can force a car to stop mid-way to let an emergency vehicle pass.

### State Transitions
*   **Non-Preemptive:** Transitions occur only from *Running* to *Waiting* or *Running* to *Terminated*.
*   **Preemptive:** Transitions can occur from *Running* to *Ready* (due to an interrupt or time-slice expiration).

## Standard Model
The standard model for comparing these two disciplines focuses on their performance characteristics across different computing environments.

| Feature | Preemptive Scheduling | Non-Preemptive Scheduling |
|---------|-----------------------|---------------------------|
| **Control** | OS forcibly interrupts processes. | Process yields control voluntarily. |
| **Overhead** | High (frequent context switches). | Low (minimal context switching). |
| **Responsiveness** | High (good for interactive systems). | Low (a long process can block others). |
| **Predictability** | Lower (execution can be interrupted). | Higher (execution is continuous). |
| **Starvation** | Possible for low-priority tasks. | Possible if a process enters an infinite loop. |
| **Data Integrity** | Requires synchronization (mutexes/locks). | Inherently safer for shared data. |

## Common Patterns

### Preemptive Patterns
1.  **Round Robin (RR):** Each process gets a small unit of CPU time (time quantum). When the time expires, the process is preempted and added to the end of the ready queue.
2.  **Shortest Remaining Time First (SRTF):** A preemptive version of SJF. If a new process arrives with a shorter remaining burst time than the current process, the current process is preempted.
3.  **Priority Scheduling (Preemptive):** If a newly arrived process has a higher priority than the currently running process, the OS preempts the CPU.

### Non-Preemptive Patterns
1.  **First-Come, First-Served (FCFS):** The simplest algorithm; the process that requests the CPU first gets it first.
2.  **Shortest Job First (SJF):** The process with the smallest CPU burst is executed next. Once started, it runs to completion.

## Anti-Patterns

### The "Convoy Effect" (Non-Preemptive)
In non-preemptive FCFS, a single CPU-bound process can cause many I/O-bound processes to wait in the ready queue for a long time, leading to poor utilization of I/O devices.

### Thrashing (Preemptive)
If the time quantum is set too small in a preemptive system, the CPU spends more time performing context switches than executing actual process instructions.

> [!CAUTION]
> Avoid setting excessively high-frequency preemption intervals in real-time systems without calculating the "Context Switch Penalty," as this can lead to total system throughput collapse.

## Edge Cases

### Kernel Preemption
While user-level processes are often preemptive, the operating system kernel itself may be non-preemptive. A "Preemptive Kernel" allows a process to be preempted even while it is executing a system call in kernel mode. This is critical for real-time systems but introduces significant complexity in managing kernel data structures.

### Priority Inversion
In preemptive systems, a high-priority task may be blocked by a low-priority task that holds a required resource (like a mutex). If a medium-priority task preempts the low-priority task, the high-priority task is effectively delayed by the medium-priority task.

### Interrupt Service Routines (ISRs)
ISRs are inherently preemptive. Even in a non-preemptive OS, a hardware interrupt will pause the current process to execute the handler. However, the OS is considered non-preemptive if it returns control *only* to the interrupted process after the ISR finishes, rather than re-evaluating the entire ready queue.

## Related Topics
*   **Context Switching:** The mechanical process of swapping process states.
*   **Process States:** The lifecycle of a process (Ready, Running, Waiting, Terminated).
*   **Real-Time Operating Systems (RTOS):** Systems where preemption is mandatory for meeting hard deadlines.
*   **Concurrency and Synchronization:** Mechanisms required to protect data when preemption occurs.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |