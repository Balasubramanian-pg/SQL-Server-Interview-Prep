# 21. Hash Buckets in Buffer Pool

Canonical documentation for [21. Hash Buckets in Buffer Pool](1. Database Architecture Internals/21. Hash Buckets in Buffer Pool.md). This document defines concepts, terminology, and standard usage.

## Purpose
The primary purpose of hash buckets within a buffer pool is to provide a high-performance indexing mechanism for locating data pages residing in memory. In a database management system (DBMS), the buffer pool acts as a cache for data stored on disk. Because the buffer pool can contain hundreds of thousands or millions of pages, a linear search to find a specific page would result in $O(N)$ complexity, which is computationally prohibitive.

Hash buckets facilitate near-constant time $O(1)$ lookups by mapping a unique page identifier (typically a combination of Space ID/Tablespace ID and Page Number) to a specific memory address or buffer frame descriptor.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural necessity of hashing in memory management.

## Scope
This document covers the structural and algorithmic role of hash buckets in memory-resident page tracking.

> [!IMPORTANT]
> **In scope:**
> * Mapping mechanisms between disk-based identifiers and memory frames.
> * Collision resolution strategies within the buffer pool context.
> * Synchronization requirements for bucket access.
> * Memory overhead considerations.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., InnoDB, Postgres, SQL Server internals).
> * Disk-level storage formats.
> * Replacement algorithms (LRU/Clock) except where they intersect with hash bucket management.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Page ID | A unique identifier for a data block, usually comprising a file or tablespace ID and an offset/page number. |
| Buffer Frame | A fixed-size memory slot in the buffer pool designated to hold one page of data. |
| Hash Bucket | A specific slot in a hash table that points to one or more page descriptors. |
| Hash Collision | A scenario where two distinct Page IDs produce the same hash value, mapping them to the same bucket. |
| Bucket Chain | A linked list of page descriptors associated with a single hash bucket, used to resolve collisions. |
| Hash Function | The algorithm used to transform a Page ID into a bucket index. |

## Core Concepts
The hash bucket system operates as the "directory" of the buffer pool. When a process requests a page, the system must determine if that page is already in memory (a "cache hit") or must be fetched from disk (a "cache miss").

### The Mapping Process
1. **Input:** The system receives a request for `Page X`.
2. **Hashing:** The `Page ID` is passed through a hash function.
3. **Indexing:** The resulting hash value determines which bucket to inspect.
4. **Traversal:** The system traverses the bucket chain (if any) to find the exact match for `Page X`.
5. **Output:** If found, the pointer to the buffer frame is returned.

> [!TIP]
> Think of hash buckets as a series of mailboxes. Instead of searching every house in a city for a person, you use their "name" (Page ID) to determine exactly which mailbox (Bucket) contains their address (Buffer Frame). Even if multiple people share a mailbox, searching that small group is much faster than searching the whole city.

## Standard Model
The standard model for buffer pool hashing involves a fixed-size or dynamically resizable array of pointers. Each pointer represents a bucket.

### Collision Resolution
Most buffer pool implementations utilize **Chaining**. In this model, each bucket points to the head of a linked list of page descriptors. When a collision occurs, the new page descriptor is simply appended to the list.

### Bucket Count
To maintain $O(1)$ performance, the number of buckets is typically a function of the total number of frames in the buffer pool. A common heuristic is to have the number of buckets be 1.2x to 2x the number of buffer frames to minimize the average length of bucket chains.

### Synchronization
In multi-threaded environments, access to hash buckets must be synchronized to prevent race conditions during page lookups or insertions. This is often achieved through:
* **Bucket-level locking:** Partitioning the hash table into segments, each protected by a separate mutex.
* **Lock-free structures:** Using atomic operations for pointer updates in the chains.

## Common Patterns
* **Power-of-Two Sizing:** Many systems round the number of buckets to the nearest power of two to allow the use of bitwise `AND` operations instead of expensive modulo `%` operations for the hash function.
* **Global Hash Table:** A single hash table serving the entire buffer pool instance.
* **Partitioned Hash Tables:** Dividing the hash table into multiple independent partitions to reduce lock contention in high-concurrency workloads.

## Anti-Patterns
* **Insufficient Bucket Count:** Using too few buckets leads to long chains, degrading performance toward $O(N)$.
* **Poor Hash Function Distribution:** A hash function that clusters Page IDs into a few buckets (hotspots) while leaving others empty.
* **Global Mutexing:** Using a single lock for the entire hash table, which creates a massive bottleneck in multi-core systems.

> [!CAUTION]
> Avoid implementations where the hash bucket management is tightly coupled with the physical page layout. This prevents the ability to resize the buffer pool or change hashing strategies without significant refactoring.

## Edge Cases
* **Buffer Pool Resizing:** When the buffer pool is dynamically grown or shrunk, the hash table must be rehashed or scaled. This is a high-overhead operation that can momentarily stall page lookups.
* **Hash Collisions on Different Tablespaces:** If the hash function only considers page numbers and ignores tablespace IDs, pages from different files will collide frequently.
* **Transient Pages:** Pages that are in the process of being read from disk or written to disk must be correctly flagged in the hash bucket to prevent duplicate I/O requests for the same Page ID.

## Related Topics
* **Buffer Pool Replacement Policy:** How pages are selected for eviction when the pool is full.
* **Page Descriptors:** The metadata structures stored in or pointed to by hash buckets.
* **Latch Management:** The low-level synchronization primitives used to protect bucket integrity.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |