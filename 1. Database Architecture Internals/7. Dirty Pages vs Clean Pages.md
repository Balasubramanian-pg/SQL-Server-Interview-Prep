# 7. Dirty Pages vs Clean Pages

Canonical documentation for [7. Dirty Pages vs Clean Pages](1. Database Architecture Internals/7. Dirty Pages vs Clean Pages.md). This document defines concepts, terminology, and standard usage.

## Purpose
The concept of Dirty and Clean pages exists to manage the discrepancy between high-speed volatile memory (RAM) and slower persistent storage (Disk). In any system that caches data—such as operating systems, database management systems (DBMS), or application-level caches—it is inefficient to write every single change to disk immediately. 

This topic addresses the problem of data synchronization, performance optimization, and durability. By categorizing memory segments (pages) based on their synchronization status, systems can defer expensive I/O operations, batch updates, and maintain a high throughput for read/write operations while managing the risks associated with data volatility.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, applying equally to operating system virtual memory and database buffer pool management.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * The lifecycle of a data page in memory.
> * The logical state transitions between "Clean" and "Dirty."
> * Synchronization mechanisms (flushing/checkpointing).
> * The impact of page states on system performance and recovery.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., specific MySQL InnoDB or PostgreSQL buffer pool internals).
> * Hardware-level cache line management (L1/L2/L3 CPU caches).
> * Specific file system protocols (e.g., NTFS vs. EXT4 internal structures).

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Page | A fixed-length contiguous block of virtual memory, described by a single entry in the page table. It is the smallest unit of data for memory management. |
| Clean Page | A page in memory that is identical to the version stored on persistent storage. |
| Dirty Page | A page in memory that has been modified by a process but has not yet been written back to persistent storage. |
| Flushing | The process of writing dirty pages from volatile memory to persistent storage to synchronize the two. |
| Eviction | The removal of a page from memory to make room for new data, often governed by algorithms like LRU (Least Recently Used). |
| Checkpoint | A point in time where the system ensures all dirty pages are flushed to disk to minimize recovery time. |

## Core Concepts
The fundamental idea behind dirty and clean pages is the **Write-Back Cache** strategy. 

When a system needs to modify data, it first loads the "Page" from disk into RAM. At this moment, the page is **Clean**. When the system updates a record within that page, the memory version becomes newer than the disk version. The page is now marked as **Dirty**.

> [!TIP]
> Think of a "Clean Page" as a library book that matches the master copy in the archives. A "Dirty Page" is like that book after you have scribbled notes in the margins; the copy in your hand is now different (and more up-to-date) than the master copy in the archives. "Flushing" is the act of updating the master copy with your new notes.

### The State Machine
1.  **Load:** Page moves from Disk to RAM (State: Clean).
2.  **Modify:** Data in RAM is updated (State: Dirty).
3.  **Flush:** Data in RAM is written to Disk (State: Clean).
4.  **Evict:** Page is removed from RAM to free space.

## Standard Model
The standard model for managing these pages involves a **Buffer Manager** or **Pager**. 

1.  **Read Request:** The system checks if the page is in memory. If not, it fetches it from disk (Clean).
2.  **Write Request:** The system marks the page as Dirty in the page table or buffer header. It does not immediately trigger a disk write.
3.  **Background Writing:** A background process periodically scans for dirty pages and flushes them to disk to keep the number of dirty pages within a manageable threshold.
4.  **Memory Pressure:** If the system runs out of RAM, it must evict pages. 
    *   If a page is **Clean**, it can be dropped immediately (it can always be re-read from disk).
    *   If a page is **Dirty**, it **must** be flushed to disk before it can be evicted to prevent data loss.

## Common Patterns
*   **Lazy Writing:** Delaying the flush until absolutely necessary (e.g., memory pressure or a scheduled checkpoint) to maximize I/O efficiency.
*   **Write-Ahead Logging (WAL):** Before a dirty page is flushed, the changes are recorded in a sequential log. This ensures that if the system crashes while pages are dirty, the changes can be reconstructed.
*   **Checkpointing:** Periodically forcing all dirty pages to disk to limit the amount of work required during crash recovery.

## Anti-Patterns
*   **Synchronous Flushing:** Writing every change to disk immediately. This eliminates the performance benefits of memory caching and leads to I/O bottlenecks.
*   **Aggressive Eviction:** Removing pages from memory too quickly, causing "thrashing" where the system repeatedly reads and writes the same pages.
*   **Ignoring Dirty Thresholds:** Allowing too many dirty pages to accumulate. This can lead to massive I/O spikes during checkpoints or long "freezes" when the system finally runs out of memory and must flush everything at once.

> [!CAUTION]
> Avoid systems where the "Dirty" flag is not protected by atomicity. If a page is being flushed while simultaneously being modified without proper locking, the data on disk may become corrupted (a "torn page").

## Edge Cases
*   **Torn Pages:** A crash occurring in the middle of flushing a dirty page, where only part of the page is written to disk. This results in a corrupted block that is neither the old version nor the new version.
*   **Double Buffering:** When the operating system and an application (like a database) both try to manage dirty pages for the same data, leading to redundant I/O and wasted RAM.
*   **Non-Volatile RAM (NVRAM):** In systems with persistent memory, the distinction between dirty and clean pages becomes blurred, as "memory" itself may survive a power loss.

## Related Topics
*   **Buffer Pool Management:** The high-level architecture that uses clean/dirty page logic.
*   **ACID Properties:** Specifically "Durability," which relies on the proper flushing of dirty pages.
*   **Virtual Memory and Paging:** The OS-level implementation of these concepts.
*   **Write-Ahead Logging (WAL):** The mechanism that protects dirty pages before they are flushed.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-11 | Initial AI-generated canonical documentation |