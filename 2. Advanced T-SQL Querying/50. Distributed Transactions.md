# 50. Distributed Transactions

### 1. The Anchor
* **One-Sentence Pitch:** Distributed transactions ensure data integrity across multiple independent databases, services, or nodes by guaranteeing that a complex sequence of operations either fully completes or leaves the system state unchanged.
* **Category:** Technical Skill / Distributed Systems Architecture

### 2. The Mechanics
* **Key Detail A: Coordination Protocols (2PC and 3PC):** The traditional approach relies on a central coordinator and two phases: the **Prepare Phase** (where participants vote to commit) and the **Commit Phase** (where the coordinator finalizes the change). While Two-Phase Commit (2PC) ensures strict consistency, it is a blocking protocol; Three-Phase Commit (3PC) introduces a "Pre-Commit" stage to reduce blocking during coordinator failures.
* **Key Detail B: The Saga Pattern and Compensating Transactions:** In modern microservices, long-lived transactions are often handled via Sagas. Instead of locking resources, a Saga executes a sequence of local transactions. If one step fails, the system triggers **Compensating Transactions**â€”undo operations that restore the system to its previous state, favoring eventual consistency over immediate consistency.
* **The Logic:** Distributed transactions solve the "Partial Failure" problem. In a distributed environment, the network is unreliable, and individual nodes can crash. Without a transactional boundary, a system might successfully charge a customer's credit card but fail to update the inventory, leading to a corrupted business state.

> [!IMPORTANT]
> Distributed transactions are governed by the **CAP Theorem**. Most implementations must choose between **Consistency** (ensuring all nodes see the same data) and **Availability** (ensuring the system remains responsive), as network partitions are inevitable.

### 3. The Evidence
* **Context (CAR/STAR):** While architecting a fintech platform, we faced a critical issue where "Transfer" operations between the Ledger service and the User-Wallet service were occasionally desynchronized due to network timeouts, resulting in "lost" funds.
* **Action:** I evaluated 2PC but rejected it due to high latency and the risk of deadlocks. Instead, I implemented an **Orchestration-based Saga Pattern**. I utilized a central orchestrator to manage the state machine of the transfer and implemented idempotent consumers to ensure that retries did not result in double-spending.
* **Result:** This implementation eliminated 100% of the manual reconciliation tasks previously required by the finance team and maintained system throughput at 5,000 transactions per second with a robust audit trail for every failure state.

> [!TIP]
> When implementing Sagas, always ensure your service endpoints are **idempotent**. This allows the system to safely retry operations without side effects if a network acknowledgment is lost.

### 4. The Interview "Pivot"
* **Triggers:** "How do you maintain data consistency in microservices?", "What are the downsides of 2PC?", "Tell me about a time you handled a complex system failure," or "Explain the difference between ACID and BASE."
* **The Connection:** This topic proves I understand the fundamental trade-offs of distributed computing. It demonstrates that I don't just build "happy path" code, but design resilient systems that account for network unreliability, partial failures, and the rigorous requirements of data-critical industries like finance and e-commerce.

> [!CAUTION]
> Avoid using distributed transactions (especially 2PC) unless absolutely necessary. They introduce significant coupling and latency. Always ask: "Can this business process accept eventual consistency?" before committing to a distributed transaction architecture.